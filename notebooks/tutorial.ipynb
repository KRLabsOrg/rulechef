{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RuleChef Tutorial\n",
    "\n",
    "RuleChef turns labeled examples into fast, deterministic rules. The key idea: **an LLM writes the rules at training time, but the rules run locally at inference time** — no API calls, sub-millisecond latency, zero cost per query.\n",
    "\n",
    "### How it works\n",
    "\n",
    "```\n",
    "Your examples ──> RuleChef + LLM ──> Learned rules (regex/code) ──> Fast local execution (<1ms)\n",
    "                   (training)           (saved to disk)               (no LLM needed)\n",
    "```\n",
    "\n",
    "The pipeline:\n",
    "\n",
    "1. **Buffer** — `add_example()` collects examples in a buffer (not used immediately)\n",
    "2. **Synthesis** — `learn_rules()` sends examples to an LLM, which writes regex/code patterns\n",
    "3. **Evaluation** — rules are tested against examples, failures drive refinement\n",
    "4. **Extraction** — `extract()` runs the learned rules locally, no LLM call\n",
    "\n",
    "The LLM is only used during `learn_rules()`. Everything else — adding examples, extracting, evaluating — runs locally.\n",
    "\n",
    "For the full architecture, see [How It Works](https://krlabsorg.github.io/rulechef/getting-started/concepts/) in the docs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Getting Started\n",
    "\n",
    "We'll set up an LLM client, define a task (medical NER), and create a RuleChef instance. The **Task** describes what we're extracting — entity types, schemas — and is used to build prompts for the LLM during rule synthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install (run once)\n",
    "# !pip install rulechef datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set your API key — any OpenAI-compatible provider works (OpenAI, Groq, Together, etc.)\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "from rulechef import RuleChef, RuleFormat, Task, TaskType\n",
    "\n",
    "# --- LLM client ---\n",
    "client = OpenAI(\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    ")\n",
    "MODEL = \"moonshotai/kimi-k2-instruct-0905\"\n",
    "\n",
    "# --- Task definition ---\n",
    "task = Task(\n",
    "    name=\"Medical Prescription NER\",\n",
    "    description=(\n",
    "        \"Extract DRUG, DOSAGE, FREQUENCY, and CONDITION entities from clinical \"\n",
    "        \"prescription text. DRUG = medication name, DOSAGE = amount/strength, \"\n",
    "        \"FREQUENCY = how often taken, CONDITION = medical condition being treated.\"\n",
    "    ),\n",
    "    input_schema={\"text\": \"str\"},\n",
    "    output_schema={\n",
    "        \"entities\": \"List[{text: str, start: int, end: int, type: DRUG|DOSAGE|FREQUENCY|CONDITION}]\"\n",
    "    },\n",
    "    type=TaskType.NER,\n",
    "    text_field=\"text\",\n",
    ")\n",
    "\n",
    "# --- Create RuleChef ---\n",
    "storage = tempfile.mkdtemp(prefix=\"rulechef_tutorial_\")\n",
    "chef = RuleChef(\n",
    "    task,\n",
    "    client,\n",
    "    dataset_name=\"medical_ner_tutorial\",\n",
    "    storage_path=storage,\n",
    "    model=MODEL,\n",
    "    allowed_formats=[RuleFormat.REGEX],  # regex-only for transparency\n",
    "    use_grex=True,  # use grex to suggest regex patterns from examples\n",
    ")\n",
    "print(f\"Storage: {storage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Display helpers (rich) ---\n",
    "# Reusable functions for inspecting rules, results, and evaluation during demos.\n",
    "# pip install rich  (or: pip install rulechef[notebooks])\n",
    "\n",
    "from rich.console import Console\n",
    "from rich.panel import Panel\n",
    "from rich.syntax import Syntax\n",
    "from rich.table import Table\n",
    "from rich.text import Text\n",
    "\n",
    "console = Console()\n",
    "\n",
    "# Entity type colors for NER highlighting\n",
    "_ENTITY_COLORS = {\n",
    "    \"DRUG\": \"bold cyan\",\n",
    "    \"DOSAGE\": \"bold yellow\",\n",
    "    \"FREQUENCY\": \"bold green\",\n",
    "    \"CONDITION\": \"bold magenta\",\n",
    "}\n",
    "_FALLBACK_COLORS = [\n",
    "    \"bold cyan\",\n",
    "    \"bold yellow\",\n",
    "    \"bold green\",\n",
    "    \"bold magenta\",\n",
    "    \"bold red\",\n",
    "    \"bold blue\",\n",
    "]\n",
    "\n",
    "\n",
    "def _color_for(entity_type, seen=None):\n",
    "    \"\"\"Get a consistent color for an entity type.\"\"\"\n",
    "    if seen is None:\n",
    "        seen = {}\n",
    "    if entity_type in _ENTITY_COLORS:\n",
    "        return _ENTITY_COLORS[entity_type]\n",
    "    if entity_type not in seen:\n",
    "        seen[entity_type] = _FALLBACK_COLORS[len(seen) % len(_FALLBACK_COLORS)]\n",
    "    return seen[entity_type]\n",
    "\n",
    "\n",
    "def _f1_color(val):\n",
    "    if val >= 0.8:\n",
    "        return \"green\"\n",
    "    if val >= 0.5:\n",
    "        return \"yellow\"\n",
    "    return \"red\"\n",
    "\n",
    "\n",
    "def show_rules(chef):\n",
    "    \"\"\"Show all rules in a compact table.\"\"\"\n",
    "    table = Table(title=\"Rules\", show_lines=False)\n",
    "    table.add_column(\"#\", style=\"dim\", width=3)\n",
    "    table.add_column(\"Name\", max_width=35)\n",
    "    table.add_column(\"Format\", width=6)\n",
    "    table.add_column(\"Pattern\", max_width=55)\n",
    "    table.add_column(\"Type\", width=12)\n",
    "    table.add_column(\"Pri\", width=3, justify=\"right\")\n",
    "    table.add_column(\"Conf\", width=5, justify=\"right\")\n",
    "\n",
    "    for i, rule in enumerate(chef.dataset.rules):\n",
    "        entity_type = \"\"\n",
    "        if rule.output_template:\n",
    "            entity_type = rule.output_template.get(\"type\", rule.output_template.get(\"label\", \"\"))\n",
    "        pattern = rule.content[:55] + \"...\" if len(rule.content) > 55 else rule.content\n",
    "        conf = rule.confidence\n",
    "        conf_style = \"green\" if conf >= 0.7 else \"yellow\" if conf >= 0.4 else \"red\"\n",
    "\n",
    "        table.add_row(\n",
    "            str(i),\n",
    "            rule.name,\n",
    "            rule.format.value,\n",
    "            pattern,\n",
    "            entity_type,\n",
    "            str(rule.priority),\n",
    "            f\"[{conf_style}]{conf:.2f}[/]\",\n",
    "        )\n",
    "    console.print(table)\n",
    "\n",
    "\n",
    "def show_rule(chef, index):\n",
    "    \"\"\"Deep dive into a single rule by index.\"\"\"\n",
    "    rules = chef.dataset.rules\n",
    "    if isinstance(index, str):\n",
    "        rule = next((r for r in rules if r.id == index), None)\n",
    "        if not rule:\n",
    "            console.print(f\"[red]Rule '{index}' not found[/]\")\n",
    "            return\n",
    "    else:\n",
    "        if index >= len(rules):\n",
    "            console.print(f\"[red]Index {index} out of range (have {len(rules)} rules)[/]\")\n",
    "            return\n",
    "        rule = rules[index]\n",
    "\n",
    "    # Header info\n",
    "    entity_type = \"\"\n",
    "    if rule.output_template:\n",
    "        entity_type = rule.output_template.get(\"type\", rule.output_template.get(\"label\", \"\"))\n",
    "    header = f\"[bold]{rule.name}[/]  |  {rule.format.value}  |  priority={rule.priority}  |  conf={rule.confidence:.2f}\"\n",
    "    if entity_type:\n",
    "        header += f\"  |  type={entity_type}\"\n",
    "\n",
    "    # Pattern with syntax highlighting\n",
    "    if rule.format.value == \"regex\":\n",
    "        syntax = Syntax(rule.content, \"perl\", theme=\"monokai\", word_wrap=True)\n",
    "    elif rule.format.value == \"code\":\n",
    "        syntax = Syntax(rule.content, \"python\", theme=\"monokai\", word_wrap=True)\n",
    "    else:\n",
    "        syntax = Syntax(rule.content, \"json\", theme=\"monokai\", word_wrap=True)\n",
    "\n",
    "    # Stats\n",
    "    stats = f\"Applied: {rule.times_applied}  |  Successes: {rule.successes}  |  Failures: {rule.failures}\"\n",
    "    if rule.times_applied > 0:\n",
    "        rate = rule.successes / rule.times_applied * 100\n",
    "        stats += f\"  |  Success rate: {rate:.0f}%\"\n",
    "\n",
    "    # Build panel content\n",
    "    content = Text()\n",
    "    content.append(stats + \"\\n\\n\")\n",
    "\n",
    "    panel = Panel.fit(\n",
    "        syntax,\n",
    "        title=header,\n",
    "        subtitle=stats,\n",
    "        border_style=\"blue\",\n",
    "    )\n",
    "    console.print(panel)\n",
    "\n",
    "    # Output template\n",
    "    if rule.output_template:\n",
    "        console.print(f\"  Output template: {rule.output_template}\")\n",
    "\n",
    "\n",
    "def show_eval(eval_result):\n",
    "    \"\"\"Show evaluation results with color-coded per-class metrics.\"\"\"\n",
    "    if not eval_result or eval_result.total_docs == 0:\n",
    "        console.print(\"[dim]No evaluation results.[/]\")\n",
    "        return\n",
    "\n",
    "    # Summary\n",
    "    f1_style = _f1_color(eval_result.micro_f1)\n",
    "    summary = Text()\n",
    "    summary.append(\"Micro F1: \")\n",
    "    summary.append(f\"{eval_result.micro_f1:.1%}\", style=f\"bold {f1_style}\")\n",
    "    summary.append(f\"  |  Macro F1: {eval_result.macro_f1:.1%}\")\n",
    "    summary.append(f\"  |  Exact match: {eval_result.exact_match:.1%}\")\n",
    "    summary.append(f\"  |  P={eval_result.micro_precision:.1%}  R={eval_result.micro_recall:.1%}\")\n",
    "    summary.append(f\"  |  {eval_result.total_docs} docs\")\n",
    "    console.print(summary)\n",
    "\n",
    "    # Per-class table\n",
    "    if eval_result.per_class:\n",
    "        table = Table(show_lines=False)\n",
    "        table.add_column(\"Class\", min_width=15)\n",
    "        table.add_column(\"F1\", justify=\"right\", width=6)\n",
    "        table.add_column(\"Prec\", justify=\"right\", width=6)\n",
    "        table.add_column(\"Recall\", justify=\"right\", width=6)\n",
    "        table.add_column(\"TP\", justify=\"right\", width=4, style=\"green\")\n",
    "        table.add_column(\"FP\", justify=\"right\", width=4, style=\"red\")\n",
    "        table.add_column(\"FN\", justify=\"right\", width=4, style=\"yellow\")\n",
    "\n",
    "        for cm in sorted(eval_result.per_class, key=lambda c: c.f1, reverse=True):\n",
    "            f1_style = _f1_color(cm.f1)\n",
    "            table.add_row(\n",
    "                cm.label,\n",
    "                f\"[{f1_style}]{cm.f1:.0%}[/]\",\n",
    "                f\"{cm.precision:.0%}\",\n",
    "                f\"{cm.recall:.0%}\",\n",
    "                str(cm.tp),\n",
    "                str(cm.fp),\n",
    "                str(cm.fn),\n",
    "            )\n",
    "        console.print(table)\n",
    "\n",
    "\n",
    "def show_failures(eval_result, entity_type=None):\n",
    "    \"\"\"Show what the FPs and FNs actually are.\n",
    "\n",
    "    Args:\n",
    "        eval_result: EvalResult from chef.evaluate() or evaluate_dataset()\n",
    "        entity_type: Optional filter — only show failures involving this type (e.g. \"FREQUENCY\")\n",
    "    \"\"\"\n",
    "    if not eval_result.failures:\n",
    "        console.print(\"[green]No failures — all examples matched![/]\")\n",
    "        return\n",
    "\n",
    "    shown = 0\n",
    "    for failure in eval_result.failures:\n",
    "        inp = failure[\"input\"]\n",
    "        expected = failure[\"expected\"]\n",
    "        got = failure[\"got\"]\n",
    "        text = inp.get(\"text\", str(inp))\n",
    "\n",
    "        # Get entity lists (NER/extraction) or labels (classification)\n",
    "        expected_entities = expected.get(\"entities\", expected.get(\"spans\", []))\n",
    "        got_entities = got.get(\"entities\", got.get(\"spans\", []))\n",
    "\n",
    "        # Classification: simple expected vs got label\n",
    "        if not expected_entities and not got_entities:\n",
    "            exp_label = expected.get(\"label\", \"\")\n",
    "            got_label = got.get(\"label\", \"\")\n",
    "            if entity_type and entity_type not in (exp_label, got_label):\n",
    "                continue\n",
    "            shown += 1\n",
    "            t = Text()\n",
    "            t.append(f\"{shown}. \", style=\"dim\")\n",
    "            t.append(text)\n",
    "            t.append(\"\\n   expected: \", style=\"dim\")\n",
    "            t.append(exp_label, style=\"green\")\n",
    "            t.append(\"   got: \", style=\"dim\")\n",
    "            t.append(got_label or \"(no match)\", style=\"red\")\n",
    "            console.print(t)\n",
    "            continue\n",
    "\n",
    "        # NER: diff expected vs got to find FPs and FNs\n",
    "        # Use list-based matching (not sets) so duplicates are caught correctly\n",
    "        def _key(e):\n",
    "            return (e.get(\"text\", \"\").lower(), e.get(\"type\", e.get(\"label\", \"\")))\n",
    "\n",
    "        remaining_expected = [_key(e) for e in expected_entities]\n",
    "        fps = []\n",
    "        for e in got_entities:\n",
    "            k = _key(e)\n",
    "            if k in remaining_expected:\n",
    "                remaining_expected.remove(k)\n",
    "            else:\n",
    "                fps.append(e)\n",
    "\n",
    "        remaining_got = [_key(e) for e in got_entities]\n",
    "        fns = []\n",
    "        for e in expected_entities:\n",
    "            k = _key(e)\n",
    "            if k in remaining_got:\n",
    "                remaining_got.remove(k)\n",
    "            else:\n",
    "                fns.append(e)\n",
    "\n",
    "        # Apply entity_type filter\n",
    "        if entity_type:\n",
    "            fps = [e for e in fps if e.get(\"type\", e.get(\"label\", \"\")) == entity_type]\n",
    "            fns = [e for e in fns if e.get(\"type\", e.get(\"label\", \"\")) == entity_type]\n",
    "            if not fps and not fns:\n",
    "                continue\n",
    "\n",
    "        shown += 1\n",
    "        t = Text()\n",
    "        t.append(f\"{shown}. \", style=\"dim\")\n",
    "        t.append(text, style=\"white\")\n",
    "        console.print(t)\n",
    "\n",
    "        # Track matched keys to detect duplicates\n",
    "        matched_keys = [_key(e) for e in got_entities if _key(e) not in [_key(f) for f in fps]]\n",
    "\n",
    "        for e in fps:\n",
    "            etype = e.get(\"type\", e.get(\"label\", \"?\"))\n",
    "            k = _key(e)\n",
    "            is_dup = k in matched_keys  # same text+type already matched as TP\n",
    "            tag = \"FP (duplicate)\" if is_dup else \"FP\"\n",
    "            console.print(f\"   [red]{tag}[/]  [{etype}: {e.get('text', '?')!r}]\")\n",
    "        for e in fns:\n",
    "            etype = e.get(\"type\", e.get(\"label\", \"?\"))\n",
    "            console.print(f\"   [yellow]FN[/]  [{etype}: {e.get('text', '?')!r}]\")\n",
    "\n",
    "    if shown == 0:\n",
    "        if entity_type:\n",
    "            console.print(f\"[dim]No failures involving {entity_type}.[/]\")\n",
    "        else:\n",
    "            console.print(\"[dim]No failures to show.[/]\")\n",
    "    else:\n",
    "        console.print(f\"\\n[dim]{shown} documents with errors[/]\")\n",
    "\n",
    "\n",
    "def test(chef, text):\n",
    "    \"\"\"Extract from text and display results with highlighted entities.\"\"\"\n",
    "    result = chef.extract({\"text\": text})\n",
    "\n",
    "    entities = result.get(\"entities\", result.get(\"spans\", []))\n",
    "    label = result.get(\"label\")\n",
    "\n",
    "    if entities:\n",
    "        # Build annotated text with colored entity spans\n",
    "        annotated = Text()\n",
    "        prev_end = 0\n",
    "        for e in sorted(entities, key=lambda x: x.get(\"start\", 0)):\n",
    "            start = e.get(\"start\", 0)\n",
    "            end = e.get(\"end\", 0)\n",
    "            etype = e.get(\"type\", \"?\")\n",
    "            color = _color_for(etype)\n",
    "\n",
    "            annotated.append(text[prev_end:start])\n",
    "            annotated.append(f\"[{etype}: \", style=\"dim\")\n",
    "            annotated.append(e.get(\"text\", text[start:end]), style=color)\n",
    "            annotated.append(\"]\", style=\"dim\")\n",
    "            prev_end = end\n",
    "        annotated.append(text[prev_end:])\n",
    "        console.print(annotated)\n",
    "    elif label:\n",
    "        console.print(Text.assemble(text, \"  →  \", (label, \"bold cyan\")))\n",
    "    else:\n",
    "        console.print(Text.assemble(text, \"  →  \", (\"(no match)\", \"dim\")))\n",
    "\n",
    "\n",
    "print(\"Display helpers loaded: show_rules, show_rule, show_eval, show_failures, test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add examples\n",
    "\n",
    "Examples go into a **buffer** first — they're not used until you call `learn_rules()`. This lets you collect a batch of examples before learning, and gives the coordinator a chance to decide the best learning strategy.\n",
    "\n",
    "We start with just 3 examples, each showing a clinical prescription and its entity spans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    (\n",
    "        \"Metformin 500mg twice daily for type 2 diabetes.\",\n",
    "        [\n",
    "            {\"text\": \"Metformin\", \"start\": 0, \"end\": 9, \"type\": \"DRUG\"},\n",
    "            {\"text\": \"500mg\", \"start\": 10, \"end\": 15, \"type\": \"DOSAGE\"},\n",
    "            {\"text\": \"twice daily\", \"start\": 16, \"end\": 27, \"type\": \"FREQUENCY\"},\n",
    "            {\"text\": \"type 2 diabetes\", \"start\": 32, \"end\": 47, \"type\": \"CONDITION\"},\n",
    "        ],\n",
    "    ),\n",
    "    (\n",
    "        \"Take lisinopril 10mg once daily for high blood pressure.\",\n",
    "        [\n",
    "            {\"text\": \"lisinopril\", \"start\": 5, \"end\": 15, \"type\": \"DRUG\"},\n",
    "            {\"text\": \"10mg\", \"start\": 16, \"end\": 20, \"type\": \"DOSAGE\"},\n",
    "            {\"text\": \"once daily\", \"start\": 21, \"end\": 31, \"type\": \"FREQUENCY\"},\n",
    "            {\"text\": \"high blood pressure\", \"start\": 36, \"end\": 55, \"type\": \"CONDITION\"},\n",
    "        ],\n",
    "    ),\n",
    "    (\n",
    "        \"Ibuprofen 400mg every 6 hours as needed for pain.\",\n",
    "        [\n",
    "            {\"text\": \"Ibuprofen\", \"start\": 0, \"end\": 9, \"type\": \"DRUG\"},\n",
    "            {\"text\": \"400mg\", \"start\": 10, \"end\": 15, \"type\": \"DOSAGE\"},\n",
    "            {\"text\": \"every 6 hours\", \"start\": 16, \"end\": 29, \"type\": \"FREQUENCY\"},\n",
    "            {\"text\": \"pain\", \"start\": 44, \"end\": 48, \"type\": \"CONDITION\"},\n",
    "        ],\n",
    "    ),\n",
    "]\n",
    "\n",
    "for text, entities in examples:\n",
    "    chef.add_example({\"text\": text}, {\"entities\": entities})\n",
    "\n",
    "# Examples sit in a buffer until we call learn_rules()\n",
    "print(chef.get_buffer_stats())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn rules\n",
    "\n",
    "`learn_rules()` is where the LLM comes in. It:\n",
    "1. **Commits** buffered examples to the dataset\n",
    "2. **Sends** examples to the LLM with a synthesis prompt\n",
    "3. **Gets back** regex rules that match the patterns in the examples\n",
    "4. **Tests** the rules against the examples and patches failures\n",
    "\n",
    "After this call, the rules are stored locally — no more LLM calls needed for extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules, eval_result = chef.learn_rules()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Inspect Everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule summary\n",
    "\n",
    "A quick overview of what was learned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_rules(chef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect a rule\n",
    "\n",
    "`show_rule(chef, index)` shows the full pattern with syntax highlighting, output template, and stats. Try different indices to explore what was learned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep dive into the first rule — see the full regex, output template, stats\n",
    "show_rule(chef, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try them out\n",
    "\n",
    "Let's test on texts the rules have **never seen**. We'll include several unseen FREQUENCY patterns — `\"at bedtime\"`, `\"each morning\"`, `\"three times a day\"` — to see how well the rules generalize beyond the training data.\n",
    "\n",
    "Take note of any gaps — we'll fix them in Part 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = [\n",
    "    \"Metformin 1000mg once daily for insulin resistance.\",  # should work\n",
    "    \"Take aspirin 81mg daily for cardiac prevention.\",  # \"Take\" prefix\n",
    "    \"Gabapentin 300mg at bedtime for nerve pain.\",  # \"at bedtime\" — unseen\n",
    "    \"Levothyroxine 100mcg each morning for hypothyroidism.\",  # \"each morning\" — unseen\n",
    "    \"Amoxicillin 500mg three times a day for strep throat.\",  # \"three times a day\" — unseen\n",
    "    \"The patient reported feeling dizzy after the procedure.\",  # no entities\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    test(chef, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How fast is it? No LLM call — just regex matching.\n",
    "%timeit chef.extract({\"text\": \"Metformin 500mg twice daily for type 2 diabetes.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training accuracy\n",
    "\n",
    "Quick check: how well do the rules do on the examples they were trained on? Even 100% here doesn't mean the rules generalize — the `test()` calls above are a better signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_eval(chef.evaluate(verbose=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per-rule metrics\n",
    "\n",
    "Which rules are pulling their weight? `get_rule_metrics()` evaluates each rule in isolation — useful for finding dead rules (0 matches) or harmful ones (low precision)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_metrics = chef.get_rule_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete a rule\n",
    "\n",
    "If a rule is dead (0 matches) or harmful, you can remove it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a dead rule (0 matches) if any\n",
    "dead = [m for m in rule_metrics if m.matches == 0]\n",
    "if dead:\n",
    "    print(f\"Deleting dead rule: {dead[0].rule_name} (id={dead[0].rule_id})\")\n",
    "    chef.delete_rule(dead[0].rule_id)\n",
    "    print(f\"Rules remaining: {len(chef.dataset.rules)}\")\n",
    "else:\n",
    "    print(\"No dead rules found — all rules match something.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Improve the Rules\n",
    "\n",
    "The rules got high accuracy on training data — but the unseen tests in Part 2 likely showed some gaps. Two tools to fix that: **corrections** (fix a specific wrong answer) and **feedback** (general domain guidance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrections\n",
    "\n",
    "Corrections are the **highest-value training signal** — they pair what the rules produced with what the output *should* be. They're always included first in the LLM prompt.\n",
    "\n",
    "The test above likely showed a gap on `\"Gabapentin 300mg at bedtime for nerve pain.\"` — `\"at bedtime\"` is a FREQUENCY pattern the rules never saw in training. Let's correct it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct the \"at bedtime\" test case from above\n",
    "test_input = {\"text\": \"Gabapentin 300mg at bedtime for nerve pain.\"}\n",
    "test(chef, test_input[\"text\"])\n",
    "\n",
    "# Add a correction — tell RuleChef what the right answer should be\n",
    "model_output = chef.extract(test_input)\n",
    "chef.add_correction(\n",
    "    test_input,\n",
    "    model_output=model_output,\n",
    "    expected_output={\n",
    "        \"entities\": [\n",
    "            {\"text\": \"Gabapentin\", \"start\": 0, \"end\": 10, \"type\": \"DRUG\"},\n",
    "            {\"text\": \"300mg\", \"start\": 11, \"end\": 16, \"type\": \"DOSAGE\"},\n",
    "            {\"text\": \"at bedtime\", \"start\": 17, \"end\": 27, \"type\": \"FREQUENCY\"},\n",
    "            {\"text\": \"nerve pain\", \"start\": 32, \"end\": 42, \"type\": \"CONDITION\"},\n",
    "        ]\n",
    "    },\n",
    "    feedback=\"FREQUENCY 'at bedtime' is a valid frequency pattern, \"\n",
    "    \"similar to 'once daily' or 'every 6 hours'.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incremental learn — patch existing rules instead of starting from scratch\n",
    "rules, eval_result = chef.learn_rules(incremental_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all unseen texts again — did the correction help?\n",
    "for text in test_texts:\n",
    "    test(chef, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedback\n",
    "\n",
    "The correction fixed one specific failure. But there are likely more — `\"each morning\"` and `\"three times a day\"` are also FREQUENCY patterns the rules may have missed.\n",
    "\n",
    "**Feedback** is broader: natural-language guidance that gets injected into the LLM's synthesis prompt, steering *all future* rule generation. A single piece of feedback can fix an entire class of errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain knowledge: help the LLM write more general FREQUENCY patterns\n",
    "chef.add_feedback(\n",
    "    \"FREQUENCY entities include patterns like 'at bedtime', 'each morning', \"\n",
    "    \"'three times a day', 'every N hours', 'as needed' — not just 'once/twice daily'. \"\n",
    "    \"Always match the FULL frequency phrase: 'once daily' is one FREQUENCY entity, \"\n",
    "    \"don't also match 'daily' alone as a separate entity. Cover these common patterns explicitly in the rules.\"\n",
    ")\n",
    "\n",
    "# Re-learn — feedback gets injected into the synthesis prompt\n",
    "rules, eval_result = chef.learn_rules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the same unseen texts from Part 2 — did feedback help generalization?\n",
    "for text in test_texts:\n",
    "    test(chef, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling strategies\n",
    "\n",
    "When you have lots of examples, RuleChef can't fit them all in the LLM prompt. It picks a subset using a **sampling strategy**:\n",
    "\n",
    "| Strategy | What it does |\n",
    "|----------|-------------|\n",
    "| `balanced` | Takes examples in order (default) |\n",
    "| `recent` | Newest examples first |\n",
    "| `diversity` | Evenly spaces picks across the dataset |\n",
    "| `uncertain` | Low-confidence examples first |\n",
    "| `varied` | Mix of recent + diverse + uncertain |\n",
    "| `corrections_first` | Corrections always go first (they already do by default, but this also sorts examples by recency) |\n",
    "\n",
    "All strategies always include corrections first — they're the highest-value signal.\n",
    "\n",
    "You can set a default strategy when creating RuleChef, or override per call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override sampling for a single learn call\n",
    "chef.learn_rules(sampling_strategy=\"diversity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Under the Hood\n",
    "\n",
    "What actually goes to the LLM? Let's look at the prompts RuleChef builds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The synthesis prompt\n",
    "\n",
    "This is the prompt that asks the LLM to generate rules from examples. It includes:\n",
    "1. **Task description** — what we're trying to do\n",
    "2. **Data evidence** — patterns found in the examples (including auto-generated regex hints from `grex`)\n",
    "3. **Training examples** — the actual input/output pairs\n",
    "4. **User feedback** — any guidance you've added\n",
    "5. **Format instructions** — how to write regex rules, with technique guides\n",
    "6. **Response schema** — the exact JSON format to return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the synthesis prompt (what the LLM sees)\n",
    "prompt = chef.learner._build_synthesis_prompt(chef.dataset, max_rules=10)\n",
    "print(f\"Prompt length: {len(prompt)} chars\")\n",
    "print(\"=\" * 80)\n",
    "print(prompt[:3000])\n",
    "print(\"\\n... (truncated) ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### grex: regex hints from examples\n",
    "\n",
    "[grex](https://github.com/pemistahl/grex) is a library that infers regex patterns from example strings. You give it strings, it gives you a regex that matches all of them. RuleChef uses this to give the LLM concrete pattern suggestions during rule synthesis.\n",
    "\n",
    "Let's first see what grex does on its own, then see how RuleChef uses it in prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "try:\n",
    "    from grex import RegExpBuilder\n",
    "\n",
    "    # Example 1: Dates — grex finds the structural pattern\n",
    "    dates = [\"2024-01-15\", \"2024-02-28\", \"2023-12-01\", \"2025-06-30\"]\n",
    "    exact = RegExpBuilder.from_test_cases(dates).without_anchors().build()\n",
    "    generalized = (\n",
    "        RegExpBuilder.from_test_cases(dates)\n",
    "        .without_anchors()\n",
    "        .with_conversion_of_digits()\n",
    "        .with_conversion_of_repetitions()\n",
    "        .build()\n",
    "    )\n",
    "    print(\"=== Dates ===\")\n",
    "    print(f\"  Input:      {dates}\")\n",
    "    print(f\"  Exact:      {exact}\")\n",
    "    print(f\"  Generalized: {generalized}\")\n",
    "    # Verify the generalized pattern matches new dates\n",
    "    print(f\"  Matches '2026-03-14'? {bool(re.search(generalized, '2026-03-14'))}\")\n",
    "    print()\n",
    "\n",
    "    # Example 2: Dollar amounts\n",
    "    amounts = [\"$10.99\", \"$5.00\", \"$249.95\", \"$1.50\"]\n",
    "    exact = RegExpBuilder.from_test_cases(amounts).without_anchors().build()\n",
    "    generalized = (\n",
    "        RegExpBuilder.from_test_cases(amounts)\n",
    "        .without_anchors()\n",
    "        .with_conversion_of_digits()\n",
    "        .with_conversion_of_repetitions()\n",
    "        .build()\n",
    "    )\n",
    "    print(\"=== Dollar amounts ===\")\n",
    "    print(f\"  Input:      {amounts}\")\n",
    "    print(f\"  Exact:      {exact}\")\n",
    "    print(f\"  Generalized: {generalized}\")\n",
    "    print()\n",
    "\n",
    "    # Example 3: Natural language — exact pattern is just alternation\n",
    "    phrases = [\"exchange rate\", \"current rates\", \"conversion rate\"]\n",
    "    exact = RegExpBuilder.from_test_cases(phrases).without_anchors().build()\n",
    "    print(\"=== Natural language phrases ===\")\n",
    "    print(f\"  Input:      {phrases}\")\n",
    "    print(f\"  Exact:      {exact}\")\n",
    "    print(\"  (No structural pattern — text is too diverse to generalize)\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"grex not installed. Install with: pip install rulechef[grex]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract just the data evidence section from the prompt\n",
    "prompt_with_grex = chef.learner._build_synthesis_prompt(chef.dataset, max_rules=10)\n",
    "\n",
    "# Find the data evidence section\n",
    "start = prompt_with_grex.find(\"DATA EVIDENCE FROM TRAINING:\")\n",
    "end = prompt_with_grex.find(\"\\n\\n\", start + 1) if start != -1 else -1\n",
    "if start != -1:\n",
    "    evidence_with = prompt_with_grex[start:end].strip()\n",
    "    print(\"=== With grex (default) ===\")\n",
    "    print(evidence_with)\n",
    "else:\n",
    "    print(\"DATA EVIDENCE section not found — grex may not be installed.\")\n",
    "    print(\"Install with: pip install rulechef[grex]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now disable grex and compare\n",
    "chef.learner.prompt_builder.use_grex = False\n",
    "prompt_without_grex = chef.learner._build_synthesis_prompt(chef.dataset, max_rules=10)\n",
    "\n",
    "start = prompt_without_grex.find(\"DATA EVIDENCE FROM TRAINING:\")\n",
    "end = prompt_without_grex.find(\"\\n\\n\", start + 1) if start != -1 else -1\n",
    "if start != -1:\n",
    "    evidence_without = prompt_without_grex[start:end].strip()\n",
    "    print(\"=== Without grex ===\")\n",
    "    print(evidence_without)\n",
    "else:\n",
    "    print(\"No DATA EVIDENCE section — this task type may not generate one.\")\n",
    "\n",
    "# Restore grex\n",
    "chef.learner.prompt_builder.use_grex = True\n",
    "\n",
    "# Show the difference\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"Prompt length WITH grex:    {len(prompt_with_grex):,} chars\")\n",
    "print(f\"Prompt length WITHOUT grex: {len(prompt_without_grex):,} chars\")\n",
    "print(f\"grex adds {len(prompt_with_grex) - len(prompt_without_grex):,} chars of regex hints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Agentic Learning\n",
    "\n",
    "So far the learning loop uses simple heuristics: \"did F1 improve? keep going.\" The **Agentic Coordinator** replaces those heuristics with an LLM that reads the per-class metrics after each iteration and writes targeted guidance: *\"FREQUENCY recall is 60% — the rules miss 'at bedtime' and 'each morning', add alternation patterns for these.\"*\n",
    "\n",
    "It also decides when to **stop early** — no point iterating if everything is at 100%.\n",
    "\n",
    "To give it a real workout, we'll add 9 more varied examples: different dosage units (`mcg`, `units`), new frequency patterns (`\"at bedtime\"`, `\"each morning\"`, `\"three times daily\"`), filler text (`\"before breakfast\"`, `\"taper over 2 weeks\"`), and a multi-word drug (`\"Insulin glargine\"`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rulechef.coordinator import AgenticCoordinator\n",
    "\n",
    "# Add more examples from the full dataset so the agentic coordinator has more to work with\n",
    "more_examples = [\n",
    "    (\n",
    "        \"Aspirin 81mg daily for cardiac prevention.\",\n",
    "        [\n",
    "            {\"text\": \"Aspirin\", \"start\": 0, \"end\": 7, \"type\": \"DRUG\"},\n",
    "            {\"text\": \"81mg\", \"start\": 8, \"end\": 12, \"type\": \"DOSAGE\"},\n",
    "            {\"text\": \"daily\", \"start\": 13, \"end\": 18, \"type\": \"FREQUENCY\"},\n",
    "            {\"text\": \"cardiac prevention\", \"start\": 23, \"end\": 41, \"type\": \"CONDITION\"},\n",
    "        ],\n",
    "    ),\n",
    "    (\n",
    "        \"Omeprazole 20mg once daily before breakfast for acid reflux.\",\n",
    "        [\n",
    "            {\"text\": \"Omeprazole\", \"start\": 0, \"end\": 10, \"type\": \"DRUG\"},\n",
    "            {\"text\": \"20mg\", \"start\": 11, \"end\": 15, \"type\": \"DOSAGE\"},\n",
    "            {\"text\": \"once daily\", \"start\": 16, \"end\": 26, \"type\": \"FREQUENCY\"},\n",
    "            {\"text\": \"acid reflux\", \"start\": 48, \"end\": 59, \"type\": \"CONDITION\"},\n",
    "        ],\n",
    "    ),\n",
    "    (\n",
    "        \"Atorvastatin 40mg at bedtime for high cholesterol.\",\n",
    "        [\n",
    "            {\"text\": \"Atorvastatin\", \"start\": 0, \"end\": 12, \"type\": \"DRUG\"},\n",
    "            {\"text\": \"40mg\", \"start\": 13, \"end\": 17, \"type\": \"DOSAGE\"},\n",
    "            {\"text\": \"at bedtime\", \"start\": 18, \"end\": 28, \"type\": \"FREQUENCY\"},\n",
    "            {\"text\": \"high cholesterol\", \"start\": 33, \"end\": 49, \"type\": \"CONDITION\"},\n",
    "        ],\n",
    "    ),\n",
    "    (\n",
    "        \"Prednisone 60mg once daily for asthma, taper over 2 weeks.\",\n",
    "        [\n",
    "            {\"text\": \"Prednisone\", \"start\": 0, \"end\": 10, \"type\": \"DRUG\"},\n",
    "            {\"text\": \"60mg\", \"start\": 11, \"end\": 15, \"type\": \"DOSAGE\"},\n",
    "            {\"text\": \"once daily\", \"start\": 16, \"end\": 26, \"type\": \"FREQUENCY\"},\n",
    "            {\"text\": \"asthma\", \"start\": 31, \"end\": 37, \"type\": \"CONDITION\"},\n",
    "        ],\n",
    "    ),\n",
    "    (\n",
    "        \"Warfarin 5mg once daily for deep vein thrombosis.\",\n",
    "        [\n",
    "            {\"text\": \"Warfarin\", \"start\": 0, \"end\": 8, \"type\": \"DRUG\"},\n",
    "            {\"text\": \"5mg\", \"start\": 9, \"end\": 12, \"type\": \"DOSAGE\"},\n",
    "            {\"text\": \"once daily\", \"start\": 13, \"end\": 23, \"type\": \"FREQUENCY\"},\n",
    "            {\"text\": \"deep vein thrombosis\", \"start\": 28, \"end\": 48, \"type\": \"CONDITION\"},\n",
    "        ],\n",
    "    ),\n",
    "    (\n",
    "        \"Sertraline 50mg once daily for generalized anxiety disorder.\",\n",
    "        [\n",
    "            {\"text\": \"Sertraline\", \"start\": 0, \"end\": 10, \"type\": \"DRUG\"},\n",
    "            {\"text\": \"50mg\", \"start\": 11, \"end\": 15, \"type\": \"DOSAGE\"},\n",
    "            {\"text\": \"once daily\", \"start\": 16, \"end\": 26, \"type\": \"FREQUENCY\"},\n",
    "            {\"text\": \"generalized anxiety disorder\", \"start\": 31, \"end\": 59, \"type\": \"CONDITION\"},\n",
    "        ],\n",
    "    ),\n",
    "    (\n",
    "        \"Levothyroxine 100mcg each morning for hypothyroidism.\",\n",
    "        [\n",
    "            {\"text\": \"Levothyroxine\", \"start\": 0, \"end\": 13, \"type\": \"DRUG\"},\n",
    "            {\"text\": \"100mcg\", \"start\": 14, \"end\": 20, \"type\": \"DOSAGE\"},\n",
    "            {\"text\": \"each morning\", \"start\": 21, \"end\": 33, \"type\": \"FREQUENCY\"},\n",
    "            {\"text\": \"hypothyroidism\", \"start\": 38, \"end\": 52, \"type\": \"CONDITION\"},\n",
    "        ],\n",
    "    ),\n",
    "    (\n",
    "        \"Insulin glargine 18 units at bedtime for diabetes mellitus.\",\n",
    "        [\n",
    "            {\"text\": \"Insulin glargine\", \"start\": 0, \"end\": 16, \"type\": \"DRUG\"},\n",
    "            {\"text\": \"18 units\", \"start\": 17, \"end\": 25, \"type\": \"DOSAGE\"},\n",
    "            {\"text\": \"at bedtime\", \"start\": 26, \"end\": 36, \"type\": \"FREQUENCY\"},\n",
    "            {\"text\": \"diabetes mellitus\", \"start\": 41, \"end\": 58, \"type\": \"CONDITION\"},\n",
    "        ],\n",
    "    ),\n",
    "    (\n",
    "        \"Gabapentin 300mg three times daily for neuropathic pain.\",\n",
    "        [\n",
    "            {\"text\": \"Gabapentin\", \"start\": 0, \"end\": 10, \"type\": \"DRUG\"},\n",
    "            {\"text\": \"300mg\", \"start\": 11, \"end\": 16, \"type\": \"DOSAGE\"},\n",
    "            {\"text\": \"three times daily\", \"start\": 17, \"end\": 34, \"type\": \"FREQUENCY\"},\n",
    "            {\"text\": \"neuropathic pain\", \"start\": 39, \"end\": 55, \"type\": \"CONDITION\"},\n",
    "        ],\n",
    "    ),\n",
    "]\n",
    "\n",
    "for text, entities in more_examples:\n",
    "    chef.add_example({\"text\": text}, {\"entities\": entities})\n",
    "\n",
    "print(f\"Buffer: {chef.get_buffer_stats()['new_examples']} new examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to agentic coordinator\n",
    "chef.coordinator = AgenticCoordinator(client, model=MODEL)\n",
    "\n",
    "# Learn with more refinement iterations — watch the coordinator's guidance\n",
    "# For NER, it will analyze per-entity-type precision/recall and guide synthesis\n",
    "rules, eval_result = chef.learn_rules(max_refinement_iterations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the results\n",
    "show_eval(chef.evaluate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule pruning\n",
    "\n",
    "After multiple refinement iterations, the ruleset can get bloated with redundant rules. Enable `prune_after_learn` and the coordinator will merge similar patterns and remove pure noise — with a safety net that reverts if quality drops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Rules before pruning: {len(chef.dataset.rules)}\")\n",
    "\n",
    "# Enable pruning\n",
    "chef.coordinator = AgenticCoordinator(client, model=MODEL, prune_after_learn=True)\n",
    "\n",
    "rules, eval_result = chef.learn_rules(max_refinement_iterations=3)\n",
    "\n",
    "print(f\"\\nRules after pruning: {len(chef.dataset.rules)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: LLM Observability\n",
    "\n",
    "What if you already have an LLM extracting entities in production? Instead of defining a task and manually labeling examples, you can **wrap your existing OpenAI client** and RuleChef will:\n",
    "\n",
    "1. **Observe** every LLM call — capturing messages and responses\n",
    "2. **Auto-discover** the task schema from the patterns it sees\n",
    "3. **Map** observations to the discovered schema\n",
    "4. **Learn rules** that replicate the LLM's behavior\n",
    "\n",
    "```\n",
    "Your code → wrapped_client.chat.completions.create(...) → LLM responds\n",
    "                         ↓ (observed)\n",
    "                   RuleChef captures raw interactions\n",
    "                         ↓ (at learn time)\n",
    "                   Discover task → Map to schema → Learn rules\n",
    "```\n",
    "\n",
    "**Zero-config**: no Task definition needed, no custom extractors. Just wrap and go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-config: observe an LLM extracting entities from prescriptions\n",
    "storage_obs = tempfile.mkdtemp(prefix=\"rulechef_observe_\")\n",
    "observer_chef = RuleChef(\n",
    "    client=client,  # No task!\n",
    "    dataset_name=\"medical_observed\",\n",
    "    storage_path=storage_obs,\n",
    "    model=MODEL,\n",
    "    allowed_formats=[RuleFormat.REGEX],\n",
    "    use_grex=True,\n",
    ")\n",
    "\n",
    "# Wrap the client — returns the same client object, now observed\n",
    "wrapped_client = observer_chef.start_observing(client, auto_learn=False)\n",
    "print(\"Observing... make some LLM calls.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Simulate your existing LLM pipeline — extract entities from prescriptions\n",
    "# RuleChef silently captures every call (messages + response).\n",
    "prescriptions = [\n",
    "    \"Metformin 500mg twice daily for type 2 diabetes.\",\n",
    "    \"Take lisinopril 10mg once daily for high blood pressure.\",\n",
    "    \"Ibuprofen 400mg every 6 hours as needed for pain.\",\n",
    "    \"Aspirin 81mg daily for cardiac prevention.\",\n",
    "    \"Omeprazole 20mg once daily before breakfast for acid reflux.\",\n",
    "    \"Atorvastatin 40mg at bedtime for high cholesterol.\",\n",
    "    \"Prednisone 60mg once daily for asthma, taper over 2 weeks.\",\n",
    "    \"Warfarin 5mg once daily for deep vein thrombosis.\",\n",
    "]\n",
    "\n",
    "system_prompt = (\n",
    "    \"Extract medical entities from the prescription text. \"\n",
    "    \"Return JSON with an 'entities' list. Each entity has: \"\n",
    "    \"'text' (exact span), 'start' (char offset), 'end' (char offset), \"\n",
    "    \"and 'type' (one of: DRUG, DOSAGE, FREQUENCY, CONDITION). \"\n",
    "    \"Return only valid JSON, no explanation.\"\n",
    ")\n",
    "\n",
    "for prescription in prescriptions:\n",
    "    response = wrapped_client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prescription},\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "    result = response.choices[0].message.content.strip()\n",
    "    try:\n",
    "        entities = json.loads(result).get(\"entities\", [])\n",
    "        types = \", \".join(e.get(\"type\", \"?\") for e in entities)\n",
    "        print(f\"{prescription[:55]:57s} → [{types}]\")\n",
    "    except Exception:\n",
    "        print(f\"{prescription[:55]:57s} → (parse error)\")\n",
    "\n",
    "# Check what was captured\n",
    "print(f\"\\nObserver stats: {observer_chef.get_buffer_stats().get('observer', {})}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn_rules() does everything:\n",
    "#   1. Discovers the task schema from raw observations (since no task was provided)\n",
    "#   2. Maps each observation to the discovered schema\n",
    "#   3. Commits mapped examples to buffer → dataset\n",
    "#   4. Synthesizes + refines rules\n",
    "rules, eval_result = observer_chef.learn_rules()\n",
    "\n",
    "# Show what was discovered\n",
    "print(f\"\\nDiscovered task: {observer_chef.task.name}\")\n",
    "print(f\"  Type: {observer_chef.task.type.value}\")\n",
    "print(f\"  Input schema: {observer_chef.task.input_schema}\")\n",
    "print(f\"  Output schema: {observer_chef.task.output_schema}\")\n",
    "\n",
    "# Stop observing — restores the original client\n",
    "observer_chef.stop_observing()\n",
    "\n",
    "# The rules work without any LLM calls\n",
    "for text in [\n",
    "    \"Warfarin 5mg once daily for deep vein thrombosis.\",\n",
    "    \"Tramadol 50mg every 6 hours for chronic back pain.\",\n",
    "]:\n",
    "    result = observer_chef.extract({\"text\": text})\n",
    "    entities = result.get(\"entities\", [])\n",
    "    print(f\"\\n{text}\")\n",
    "    for e in entities:\n",
    "        print(f\"  [{e.get('type', '?')}] {e.get('text', '?')!r}\")\n",
    "    if not entities:\n",
    "        print(\"  (no entities)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Scale Up\n",
    "\n",
    "Everything above used NER on hand-crafted prescriptions. But does RuleChef work on real, messy data — and on a different task type?\n",
    "\n",
    "[Banking77](https://huggingface.co/datasets/legacy-datasets/banking77) has 13,000 banking customer queries across 77 intent classes. We'll pick a subset of classes, feed RuleChef all available training data, and let the **agentic coordinator** handle the rest — per-class synthesis, targeted refinement, early stopping.\n",
    "\n",
    "Key settings to experiment with:\n",
    "- `CLASSES` — which classes to learn (try more or fewer)\n",
    "- `max_refinement_iterations` — how many refinement rounds (more = better but slower)\n",
    "- `use_grex` — regex hints from example strings\n",
    "- `AgenticCoordinator` — LLM-guided refinement that steers toward weak classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from collections import defaultdict\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from rulechef.coordinator import AgenticCoordinator\n",
    "from rulechef.core import Dataset, Example\n",
    "\n",
    "# --- Configuration ---\n",
    "CLASSES = [\n",
    "    \"exchange_rate\",\n",
    "    \"card_arrival\",\n",
    "    \"beneficiary_not_allowed\",\n",
    "    \"disposable_card_limits\",\n",
    "    \"pending_cash_withdrawal\",\n",
    "]\n",
    "MAX_REFINEMENT_ITERATIONS = 15  # more iterations = better rules, slower learning\n",
    "\n",
    "# --- Task definition ---\n",
    "banking_task = Task(\n",
    "    name=\"Banking Intent Classification\",\n",
    "    description=(\n",
    "        f\"Classify banking customer queries into one of these intents: {', '.join(CLASSES)}\"\n",
    "    ),\n",
    "    input_schema={\"text\": \"str\"},\n",
    "    output_schema={\"label\": \"str\"},\n",
    "    type=TaskType.CLASSIFICATION,\n",
    "    text_field=\"text\",\n",
    ")\n",
    "\n",
    "# --- Load Banking77 ---\n",
    "ds = load_dataset(\"legacy-datasets/banking77\")\n",
    "label_names = ds[\"train\"].features[\"label\"].names\n",
    "\n",
    "train_records = [{\"text\": r[\"text\"], \"label\": label_names[r[\"label\"]]} for r in ds[\"train\"]]\n",
    "test_records = [{\"text\": r[\"text\"], \"label\": label_names[r[\"label\"]]} for r in ds[\"test\"]]\n",
    "\n",
    "# Split by class\n",
    "by_label = defaultdict(list)\n",
    "for ex in train_records:\n",
    "    if ex[\"label\"] in CLASSES:\n",
    "        by_label[ex[\"label\"]].append(ex)\n",
    "\n",
    "train_data = [ex for label in sorted(CLASSES) for ex in by_label[label]]\n",
    "test_data = [ex for ex in test_records if ex[\"label\"] in CLASSES]\n",
    "\n",
    "print(f\"Banking77: {len(label_names)} total classes, using {len(CLASSES)}\")\n",
    "print(f\"Training:  {len(train_data)} examples\")\n",
    "print(f\"Test:      {len(test_data)} examples (held out)\")\n",
    "for label in sorted(CLASSES):\n",
    "    print(f\"  {label:30s} | {len(by_label[label]):3d} train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data\n",
    "print(\"\\nExample record:\")\n",
    "print(train_data[0])\n",
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage2 = tempfile.mkdtemp(prefix=\"rulechef_banking77_\")\n",
    "\n",
    "chef2 = RuleChef(\n",
    "    banking_task,\n",
    "    client,\n",
    "    dataset_name=\"banking77_5class\",\n",
    "    storage_path=storage2,\n",
    "    model=MODEL,\n",
    "    allowed_formats=[RuleFormat.REGEX],\n",
    "    use_grex=True,  # regex hints from examples\n",
    "    max_samples=100,  # max examples per LLM prompt (per-class + patches)\n",
    "    max_rules_per_class=10,  # rules generated per class\n",
    "    max_counter_examples=10,  # negative examples per class prompt\n",
    "    coordinator=AgenticCoordinator(\n",
    "        client, model=MODEL\n",
    "    ),  # LLM-guided refinement + per-class synthesis\n",
    ")\n",
    "\n",
    "for ex in train_data:\n",
    "    chef2.add_example({\"text\": ex[\"text\"]}, {\"label\": ex[\"label\"]})\n",
    "\n",
    "print(f\"Added {len(train_data)} examples, learning...\")\n",
    "rules, eval_result = chef2.learn_rules(max_refinement_iterations=MAX_REFINEMENT_ITERATIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on held-out test data\n",
    "\n",
    "The rules were learned from the training split. Let's see how they generalize to a fully held-out test set — examples the rules have never seen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from rulechef.evaluation import evaluate_dataset\n",
    "\n",
    "# Build a held-out test Dataset\n",
    "test_dataset = Dataset(name=\"banking77_test\", task=banking_task)\n",
    "for ex in test_data:\n",
    "    test_dataset.examples.append(\n",
    "        Example(\n",
    "            id=str(uuid.uuid4())[:8],\n",
    "            input={\"text\": ex[\"text\"]},\n",
    "            expected_output={\"label\": ex[\"label\"]},\n",
    "            source=\"benchmark\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Evaluate on test set\n",
    "t0 = time.time()\n",
    "test_eval = evaluate_dataset(rules, test_dataset, chef2.learner._apply_rules)\n",
    "elapsed = time.time() - t0\n",
    "\n",
    "print(\n",
    "    f\"Held-out test: {len(test_data)} examples, {len(rules)} rules, {elapsed / len(test_data) * 1000:.2f}ms/query\"\n",
    ")\n",
    "show_eval(test_eval)\n",
    "show_failures(test_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persistence\n",
    "\n",
    "Rules are automatically saved to disk as JSON. You can reload them by creating a new `RuleChef` with the same `dataset_name` and `storage_path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Show the saved file\n",
    "saved_file = Path(storage2) / \"banking77_5class.json\"\n",
    "data = json.loads(saved_file.read_text())\n",
    "print(f\"Saved to: {saved_file}\")\n",
    "print(f\"File size: {saved_file.stat().st_size / 1024:.1f} KB\")\n",
    "print(f\"Contains: {len(data.get('rules', []))} rules, {len(data.get('examples', []))} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate chef from disk — rules load automatically\n",
    "chef3 = RuleChef(\n",
    "    banking_task,\n",
    "    client,\n",
    "    dataset_name=\"banking77_5class\",\n",
    "    storage_path=storage2,\n",
    "    model=MODEL,\n",
    "    allowed_formats=[RuleFormat.REGEX],\n",
    ")\n",
    "print(f\"Loaded {len(chef3.dataset.rules)} rules from disk\")\n",
    "\n",
    "# Works immediately\n",
    "result = chef3.extract({\"text\": \"what's the exchange rate for dollars?\"})\n",
    "print(f\"Extract: {result}\")\n",
    "\n",
    "# Measure throughput\n",
    "t0 = time.time()\n",
    "for ex in test_data[:100]:\n",
    "    chef3.extract({\"text\": ex[\"text\"]})\n",
    "elapsed = time.time() - t0\n",
    "print(f\"\\n100 queries in {elapsed * 1000:.1f}ms ({elapsed / 100 * 1000:.2f}ms per query)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial you learned how to use RuleChef on a medical NER task (extracting DRUG, DOSAGE, FREQUENCY, and CONDITION entities from prescription text), then benchmarked it on a classification task to show it works across task types.\n",
    "\n",
    "| # | What you learned | Key API |\n",
    "|---|-----------------|---------| \n",
    "| 1 | Define a task — describe entity types and schema | `Task(...)` |\n",
    "| 2 | Add examples — input text + labeled entity spans | `chef.add_example()` |\n",
    "| 3 | Learn rules — the LLM writes regex rules from examples | `chef.learn_rules()` |\n",
    "| 4 | Inspect rules — see patterns, entity types, priorities | `chef.get_rules_summary()`, `chef.dataset.rules` |\n",
    "| 5 | Extract — run NER with sub-ms latency, no LLM needed | `chef.extract()` |\n",
    "| 6 | Evaluate — precision/recall/F1 per entity type and per rule | `chef.evaluate()`, `chef.get_rule_metrics()` |\n",
    "| 7 | Correct mistakes — add corrections and re-learn incrementally | `chef.add_correction()` |\n",
    "| 8 | Give feedback — steer rule generation with natural language | `chef.add_feedback()` |\n",
    "| 9 | Sampling strategies — control which examples the LLM sees | `sampling_strategy=\"diversity\"` |\n",
    "| 10 | Under the hood — inspect synthesis and patch prompts, grex hints | `learner._build_synthesis_prompt()` |\n",
    "| 11 | Agentic learning — LLM-guided refinement per entity type | `AgenticCoordinator` |\n",
    "| 12 | Rule pruning — merge redundant rules with safety net | `prune_after_learn=True` |\n",
    "| 13 | LLM observability — wrap your client, auto-discover task, learn rules | `chef.start_observing()` |\n",
    "| 14 | Scale up — from 3 examples to a real benchmark dataset | `Banking77` |\n",
    "| 15 | Persistence — rules save to disk and reload automatically | `storage_path=` |\n",
    "\n",
    "**Docs & further reading:**\n",
    "- [How It Works](https://krlabsorg.github.io/rulechef/getting-started/concepts/) — architecture, buffer, rules, schemas, coordinators\n",
    "- [Full documentation](https://krlabsorg.github.io/rulechef) — installation, guides, API reference\n",
    "- [Task types](https://krlabsorg.github.io/rulechef/guide/task-types/) — NER, extraction, classification, transformation\n",
    "- [Learning & refinement](https://krlabsorg.github.io/rulechef/guide/learning/) — buffer architecture, sampling, incremental patching\n",
    "- [Evaluation & feedback](https://krlabsorg.github.io/rulechef/guide/evaluation/) — metrics, corrections, custom matchers\n",
    "- [Coordinators](https://krlabsorg.github.io/rulechef/guide/coordinators/) — simple vs agentic, rule pruning\n",
    "- [Advanced features](https://krlabsorg.github.io/rulechef/guide/advanced/) — observation mode, spaCy patterns, training data logger\n",
    "- [GitHub](https://github.com/KRLabsOrg/rulechef)\n",
    "\n",
    "**What to try next:**\n",
    "- Add more examples from your own data\n",
    "- Use corrections when the extractor misses entities\n",
    "- Try `RuleFormat.CODE` for more complex matching logic (e.g., drug name lists)\n",
    "- Try `RuleFormat.SPACY` for dependency-aware patterns\n",
    "- Use the CLI for interactive exploration: `rulechef`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chef",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
